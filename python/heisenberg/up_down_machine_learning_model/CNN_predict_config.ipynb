{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset,Dataset,DataLoader,random_split\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# new_dir = os.path.join('/'.join(os.path.abspath(os.getcwd()).split('/')[:-1]))\n",
    "# sys.path.append(new_dir)\n",
    "# from up_down_model import Up_down_flip_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.npy', 'rb') as f:\n",
    "    config = np.load(f)\n",
    "    sample_num = config.shape[0]\n",
    "    config = config.reshape([sample_num,2,4,4])\n",
    "theta,beta = config[:,0,:,:], config[:,1,:,:]\n",
    "z = np.cos(theta)\n",
    "z[z<0] = 0\n",
    "z = z.reshape(sample_num,1,4,4)\n",
    "\n",
    "with open('J.npy', 'rb') as f:\n",
    "    J = np.load(f)\n",
    "\n",
    "\n",
    "with open('energy.npy', 'rb') as f:\n",
    "    # energy 都是负的，在这里取 正值\n",
    "    energy = -np.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1, 4, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TensorDataset(torch.tensor(J).float().to(DEVICE),torch.tensor(z).float().to(DEVICE))\n",
    "\n",
    "n_train = int(len(data)*0.8)\n",
    "n_valid = len(data) - n_train\n",
    "ds_train,ds_valid = random_split(data,[n_train,n_valid])\n",
    "\n",
    "dl_train,dl_valid = DataLoader(ds_train,batch_size = 4),DataLoader(ds_valid,batch_size = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32])\n",
      "torch.Size([4, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "for features,labels in dl_train:\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expander(nn.Module):\n",
    "    def __init__(self, in_para=32, out_para=480000):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(in_para,out_para)\n",
    "    def forward(self,x):\n",
    "        x = self.linear(x)\n",
    "        sample_num = x.shape[0]\n",
    "        x = x.reshape(sample_num,3,400,400)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3, 400, 400])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expander = Expander()\n",
    "expander(torch.tensor(J).float()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv2(self.relu(self.conv1(x))))\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=(3,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        self.pool       = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yibo/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 568, 568])\n",
      "torch.Size([1, 128, 280, 280])\n",
      "torch.Size([1, 256, 136, 136])\n",
      "torch.Size([1, 512, 64, 64])\n",
      "torch.Size([1, 1024, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "# input image\n",
    "x    = torch.randn(1, 3, 572, 572)\n",
    "ftrs = encoder(x)\n",
    "for ftr in ftrs: print(ftr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.chs        = chs\n",
    "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
    "        \n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            enc_ftrs = self.crop(encoder_features[i], x)\n",
    "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
    "            x        = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    \n",
    "    def crop(self, enc_ftrs, x):\n",
    "        _, _, H, W = x.shape\n",
    "        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n",
    "        return enc_ftrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 388, 388])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder()\n",
    "x = torch.randn(1, 1024, 28, 28)\n",
    "decoder(x, ftrs[::-1][1:]).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shrinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shrinker(nn.Module):\n",
    "    def __init__(self,input_H,input_W):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(input_H*input_W,16)\n",
    "    def forward(self,x):\n",
    "        sample_num = x.shape[0]\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = x.reshape(sample_num,1,4,4)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 4, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrinker = Shrinker(228,228)\n",
    "input_data = torch.randn(32,1,228,228)\n",
    "shrinker(input_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, enc_chs=(3,64,128,256,512,1024), dec_chs=(1024, 512, 256, 128, 64), num_class=1, retain_dim=False, out_sz=(572,572)):\n",
    "        super().__init__()\n",
    "        self.expander    = Expander()\n",
    "        self.encoder     = Encoder(enc_chs)\n",
    "        self.decoder     = Decoder(dec_chs)\n",
    "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
    "        self.retain_dim  = retain_dim\n",
    "        self.out_sz      = out_sz\n",
    "        self.shrinker    = Shrinker(212,212)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x        = self.expander(x)\n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out      = self.head(out)\n",
    "        if self.retain_dim:\n",
    "            out = F.interpolate(out, self.out_sz)\n",
    "        out      = self.shrinker(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet = UNet()\n",
    "test_J = torch.tensor(J[:2,:]).float()\n",
    "unet(test_J).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "model.to(DEVICE)\n",
    "model.optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)\n",
    "model.loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "model.metric_func = lambda y_pred,y_true: torch.mean(1-torch.abs(y_true-y_pred))\n",
    "model.metric_name = \"auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.693560779094696, 0.45922672748565674)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_step(model,features,labels):\n",
    "    \n",
    "    # 训练模式，dropout层发生作用\n",
    "    model.train()\n",
    "    \n",
    "    # 梯度清零\n",
    "    model.optimizer.zero_grad()\n",
    "    \n",
    "    # 正向传播求损失\n",
    "    predictions = model(features)\n",
    "    loss = model.loss_func(predictions,labels)\n",
    "    metric = model.metric_func(predictions,labels)\n",
    "\n",
    "    # 反向传播求梯度\n",
    "    loss.backward()\n",
    "    model.optimizer.step()\n",
    "\n",
    "    return loss.item(),metric.item()\n",
    "\n",
    "def valid_step(model,features,labels):\n",
    "    \n",
    "    # 预测模式，dropout层不发生作用\n",
    "    model.eval()\n",
    "    # 关闭梯度计算\n",
    "    with torch.no_grad():\n",
    "        predictions = model(features)\n",
    "        loss = model.loss_func(predictions,labels)\n",
    "        metric = model.metric_func(predictions,labels)\n",
    "    \n",
    "    return loss.item(), metric.item()\n",
    "\n",
    "\n",
    "# 测试train_step效果\n",
    "features,labels = next(iter(dl_train))\n",
    "train_step(model,features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,epochs,dl_train,dl_valid,log_step_freq):\n",
    "\n",
    "    metric_name = model.metric_name\n",
    "    print(\"Start Training...\")\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"==========\"*8 + \"%s\"%nowtime)\n",
    "    df = pd.DataFrame([], columns=['EPOCH','loss','auc','val_loss','val_auc'])\n",
    "    for epoch in range(1,epochs+1):  \n",
    "\n",
    "        # 1，训练循环-------------------------------------------------\n",
    "        loss_sum = 0.0\n",
    "        metric_sum = 0.0\n",
    "        step = 1\n",
    "\n",
    "        for step, (features,labels) in enumerate(dl_train, 1):\n",
    "\n",
    "            loss,metric = train_step(model,features,labels)\n",
    "\n",
    "            # 打印batch级别日志\n",
    "            loss_sum += loss\n",
    "            metric_sum += metric\n",
    "            if step%log_step_freq == 0:   \n",
    "                print((\"[step = %d] loss: %.3f, \"+metric_name+\": %.3f\") %\n",
    "                      (step, loss_sum/step, metric_sum/step))\n",
    "\n",
    "        # 2，验证循环-------------------------------------------------\n",
    "        val_loss_sum = 0.0\n",
    "        val_metric_sum = 0.0\n",
    "        val_step = 1\n",
    "\n",
    "        for val_step, (features,labels) in enumerate(dl_valid, 1):\n",
    "\n",
    "            val_loss,val_metric = valid_step(model,features,labels)\n",
    "\n",
    "            val_loss_sum += val_loss\n",
    "            val_metric_sum += val_metric\n",
    "\n",
    "        # 3，记录日志-------------------------------------------------\n",
    "        info = (epoch, loss_sum/step, metric_sum/step, \n",
    "                val_loss_sum/val_step, val_metric_sum/val_step)\n",
    "        df = df.append(pd.DataFrame([info], columns=['EPOCH','loss','auc','val_loss','val_auc']),ignore_index=True)\n",
    "        # 打印epoch级别日志\n",
    "        print((\"\\nEPOCH = %d, loss = %.3f,\"+ metric_name + \\\n",
    "              \"  = %.3f, val_loss = %.3f, \"+\"val_\"+ metric_name+\" = %.3f\") \n",
    "              %info)\n",
    "        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "    print('Finished Training...')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "================================================================================2021-10-13 12:00:43\n",
      "[step = 5] loss: 0.693, auc: 0.456\n",
      "[step = 10] loss: 0.696, auc: 0.465\n",
      "[step = 15] loss: 0.695, auc: 0.460\n",
      "[step = 20] loss: 0.694, auc: 0.461\n",
      "[step = 25] loss: 0.695, auc: 0.467\n",
      "[step = 30] loss: 0.695, auc: 0.467\n",
      "[step = 35] loss: 0.695, auc: 0.470\n",
      "[step = 40] loss: 0.695, auc: 0.467\n",
      "[step = 45] loss: 0.695, auc: 0.468\n",
      "[step = 50] loss: 0.695, auc: 0.468\n",
      "[step = 55] loss: 0.694, auc: 0.466\n",
      "[step = 60] loss: 0.694, auc: 0.467\n",
      "[step = 65] loss: 0.694, auc: 0.469\n",
      "[step = 70] loss: 0.694, auc: 0.472\n",
      "[step = 75] loss: 0.694, auc: 0.473\n",
      "[step = 80] loss: 0.694, auc: 0.474\n",
      "[step = 85] loss: 0.694, auc: 0.476\n",
      "[step = 90] loss: 0.694, auc: 0.476\n",
      "[step = 95] loss: 0.694, auc: 0.476\n",
      "[step = 100] loss: 0.694, auc: 0.476\n",
      "[step = 105] loss: 0.694, auc: 0.476\n",
      "[step = 110] loss: 0.694, auc: 0.476\n",
      "[step = 115] loss: 0.694, auc: 0.475\n",
      "[step = 120] loss: 0.694, auc: 0.476\n",
      "[step = 125] loss: 0.694, auc: 0.476\n",
      "[step = 130] loss: 0.694, auc: 0.477\n",
      "[step = 135] loss: 0.694, auc: 0.477\n",
      "[step = 140] loss: 0.694, auc: 0.476\n",
      "[step = 145] loss: 0.694, auc: 0.475\n",
      "[step = 150] loss: 0.694, auc: 0.476\n",
      "[step = 155] loss: 0.694, auc: 0.477\n",
      "[step = 160] loss: 0.694, auc: 0.478\n",
      "[step = 165] loss: 0.694, auc: 0.477\n",
      "[step = 170] loss: 0.694, auc: 0.478\n",
      "[step = 175] loss: 0.694, auc: 0.478\n",
      "[step = 180] loss: 0.694, auc: 0.479\n",
      "[step = 185] loss: 0.694, auc: 0.480\n",
      "[step = 190] loss: 0.694, auc: 0.480\n",
      "[step = 195] loss: 0.694, auc: 0.480\n",
      "[step = 200] loss: 0.694, auc: 0.480\n",
      "\n",
      "EPOCH = 1, loss = 0.694,auc  = 0.480, val_loss = 0.693, val_auc = 0.505\n",
      "\n",
      "================================================================================2021-10-13 12:01:08\n",
      "Finished Training...\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "history = train_model(model,epochs,dl_train,dl_valid,log_step_freq = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试model效果\n",
    "features_test,labels_test = next(iter(dl_valid))\n",
    "# labels = labels.reshape(8,1)\n",
    "predictions_test = model(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
